{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "%matplotlib inline\n",
    "\n",
    "filename = './ml_python_labexam_2023_02_03.csv'\n",
    "separator = ','"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X00</th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.026036</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>0.104545</td>\n",
       "      <td>0.352163</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>-0.007113</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>3.288439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011618</td>\n",
       "      <td>0.025699</td>\n",
       "      <td>-0.026818</td>\n",
       "      <td>0.053014</td>\n",
       "      <td>0.613195</td>\n",
       "      <td>-0.012447</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>-0.036920</td>\n",
       "      <td>-0.016464</td>\n",
       "      <td>-2.333510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>-0.020700</td>\n",
       "      <td>0.630085</td>\n",
       "      <td>0.612415</td>\n",
       "      <td>-0.004157</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>-0.012983</td>\n",
       "      <td>2.259783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003170</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.028924</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>-0.021192</td>\n",
       "      <td>-0.011102</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>2.939127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.039508</td>\n",
       "      <td>-0.009104</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.951426</td>\n",
       "      <td>0.778600</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.012900</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>1.623948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X00       X01       X02       X03       X04       X05       X06  \\\n",
       "0 -0.016771 -0.026036 -0.001474  0.104545  0.352163  0.023372  0.003706   \n",
       "1 -0.011618  0.025699 -0.026818  0.053014  0.613195 -0.012447  0.029382   \n",
       "2  0.027478  0.009282 -0.020700  0.630085  0.612415 -0.004157  0.008240   \n",
       "3 -0.003170 -0.001697 -0.028924  0.389900  0.000182  0.027526  0.012792   \n",
       "4 -0.039508 -0.009104  0.021215  0.951426  0.778600  0.018246 -0.000294   \n",
       "\n",
       "        X07       X08       X09         y  \n",
       "0  0.004963 -0.007113  0.022166  3.288439  \n",
       "1 -0.006348 -0.036920 -0.016464 -2.333510  \n",
       "2  0.019062  0.010821 -0.012983  2.259783  \n",
       "3 -0.021192 -0.011102  0.015352  2.939127  \n",
       "4 -0.012900  0.004178  0.014846  1.623948  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename, sep=separator)\n",
    "# we now explore the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 1000 rows and 11 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X00</th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>3.378287e-01</td>\n",
       "      <td>2.521912e-01</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.437747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023475</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.019124</td>\n",
       "      <td>2.952473e-01</td>\n",
       "      <td>2.877240e-01</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.019349</td>\n",
       "      <td>0.017783</td>\n",
       "      <td>0.018999</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>2.407762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.074550</td>\n",
       "      <td>-0.055749</td>\n",
       "      <td>-0.063489</td>\n",
       "      <td>9.531015e-07</td>\n",
       "      <td>6.913766e-10</td>\n",
       "      <td>-0.054694</td>\n",
       "      <td>-0.058531</td>\n",
       "      <td>-0.054578</td>\n",
       "      <td>-0.062925</td>\n",
       "      <td>-0.073059</td>\n",
       "      <td>-6.609545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.015763</td>\n",
       "      <td>-0.012357</td>\n",
       "      <td>-0.013722</td>\n",
       "      <td>6.778294e-02</td>\n",
       "      <td>1.552023e-02</td>\n",
       "      <td>-0.011251</td>\n",
       "      <td>-0.013393</td>\n",
       "      <td>-0.011797</td>\n",
       "      <td>-0.012001</td>\n",
       "      <td>-0.018202</td>\n",
       "      <td>-1.200759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>2.638645e-01</td>\n",
       "      <td>1.218160e-01</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>0.336424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.015529</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>5.712697e-01</td>\n",
       "      <td>4.295876e-01</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>2.175038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.079599</td>\n",
       "      <td>0.073114</td>\n",
       "      <td>0.052593</td>\n",
       "      <td>9.996939e-01</td>\n",
       "      <td>9.988956e-01</td>\n",
       "      <td>0.053673</td>\n",
       "      <td>0.051803</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>7.915506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X00          X01          X02           X03           X04  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1.000000e+03  1.000000e+03   \n",
       "mean      0.000127     0.000297    -0.000421  3.378287e-01  2.521912e-01   \n",
       "std       0.023475     0.018878     0.019124  2.952473e-01  2.877240e-01   \n",
       "min      -0.074550    -0.055749    -0.063489  9.531015e-07  6.913766e-10   \n",
       "25%      -0.015763    -0.012357    -0.013722  6.778294e-02  1.552023e-02   \n",
       "50%       0.000446     0.000269    -0.000891  2.638645e-01  1.218160e-01   \n",
       "75%       0.015529     0.013924     0.012571  5.712697e-01  4.295876e-01   \n",
       "max       0.079599     0.073114     0.052593  9.996939e-01  9.988956e-01   \n",
       "\n",
       "               X05          X06          X07          X08          X09  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.000364    -0.000191     0.000553     0.000130     0.000524   \n",
       "std       0.017402     0.019349     0.017783     0.018999     0.025391   \n",
       "min      -0.054694    -0.058531    -0.054578    -0.062925    -0.073059   \n",
       "25%      -0.011251    -0.013393    -0.011797    -0.012001    -0.018202   \n",
       "50%       0.000675    -0.000333     0.000422    -0.000858    -0.000219   \n",
       "75%       0.012217     0.012797     0.012697     0.012722     0.018642   \n",
       "max       0.053673     0.051803     0.049480     0.061867     0.081461   \n",
       "\n",
       "                 y  \n",
       "count  1000.000000  \n",
       "mean      0.437747  \n",
       "std       2.407762  \n",
       "min      -6.609545  \n",
       "25%      -1.200759  \n",
       "50%       0.336424  \n",
       "75%       2.175038  \n",
       "max       7.915506  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Dataset with {df.shape[0]} rows and {df.shape[1]} columns')\n",
    "target = 'y'\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.box(figsize=(20, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X00</th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X00</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170854</td>\n",
       "      <td>-0.395194</td>\n",
       "      <td>-0.043222</td>\n",
       "      <td>-0.023247</td>\n",
       "      <td>-0.275844</td>\n",
       "      <td>0.280314</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>-0.325324</td>\n",
       "      <td>-0.153477</td>\n",
       "      <td>0.227594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X01</th>\n",
       "      <td>0.170854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308342</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>-0.059226</td>\n",
       "      <td>0.102338</td>\n",
       "      <td>0.047167</td>\n",
       "      <td>0.086368</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>-0.268953</td>\n",
       "      <td>0.170725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X02</th>\n",
       "      <td>-0.395194</td>\n",
       "      <td>-0.308342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028499</td>\n",
       "      <td>0.036766</td>\n",
       "      <td>-0.266042</td>\n",
       "      <td>-0.326706</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.195065</td>\n",
       "      <td>0.112824</td>\n",
       "      <td>-0.287004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X03</th>\n",
       "      <td>-0.043222</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.028499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049209</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>-0.006292</td>\n",
       "      <td>-0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X04</th>\n",
       "      <td>-0.023247</td>\n",
       "      <td>-0.059226</td>\n",
       "      <td>0.036766</td>\n",
       "      <td>-0.049209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018662</td>\n",
       "      <td>-0.048011</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X05</th>\n",
       "      <td>-0.275844</td>\n",
       "      <td>0.102338</td>\n",
       "      <td>-0.266042</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>-0.018662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>-0.292621</td>\n",
       "      <td>0.115454</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>0.369986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X06</th>\n",
       "      <td>0.280314</td>\n",
       "      <td>0.047167</td>\n",
       "      <td>-0.326706</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>-0.048011</td>\n",
       "      <td>0.119608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.228867</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>-0.274311</td>\n",
       "      <td>0.376340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X07</th>\n",
       "      <td>0.243400</td>\n",
       "      <td>0.086368</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>-0.292621</td>\n",
       "      <td>-0.228867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.145627</td>\n",
       "      <td>-0.132451</td>\n",
       "      <td>-0.056175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X08</th>\n",
       "      <td>-0.325324</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>0.195065</td>\n",
       "      <td>0.029519</td>\n",
       "      <td>-0.006653</td>\n",
       "      <td>0.115454</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>-0.145627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.316079</td>\n",
       "      <td>0.209655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X09</th>\n",
       "      <td>-0.153477</td>\n",
       "      <td>-0.268953</td>\n",
       "      <td>0.112824</td>\n",
       "      <td>-0.006292</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>-0.274311</td>\n",
       "      <td>-0.132451</td>\n",
       "      <td>-0.316079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.227594</td>\n",
       "      <td>0.170725</td>\n",
       "      <td>-0.287004</td>\n",
       "      <td>-0.005415</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.369986</td>\n",
       "      <td>0.376340</td>\n",
       "      <td>-0.056175</td>\n",
       "      <td>0.209655</td>\n",
       "      <td>0.374650</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X00       X01       X02       X03       X04       X05       X06  \\\n",
       "X00  1.000000  0.170854 -0.395194 -0.043222 -0.023247 -0.275844  0.280314   \n",
       "X01  0.170854  1.000000 -0.308342  0.015840 -0.059226  0.102338  0.047167   \n",
       "X02 -0.395194 -0.308342  1.000000  0.028499  0.036766 -0.266042 -0.326706   \n",
       "X03 -0.043222  0.015840  0.028499  1.000000 -0.049209  0.008271  0.011157   \n",
       "X04 -0.023247 -0.059226  0.036766 -0.049209  1.000000 -0.018662 -0.048011   \n",
       "X05 -0.275844  0.102338 -0.266042  0.008271 -0.018662  1.000000  0.119608   \n",
       "X06  0.280314  0.047167 -0.326706  0.011157 -0.048011  0.119608  1.000000   \n",
       "X07  0.243400  0.086368  0.043103 -0.006028 -0.002504 -0.292621 -0.228867   \n",
       "X08 -0.325324  0.009363  0.195065  0.029519 -0.006653  0.115454  0.054893   \n",
       "X09 -0.153477 -0.268953  0.112824 -0.006292  0.042886  0.021566 -0.274311   \n",
       "y    0.227594  0.170725 -0.287004 -0.005415  0.002213  0.369986  0.376340   \n",
       "\n",
       "          X07       X08       X09         y  \n",
       "X00  0.243400 -0.325324 -0.153477  0.227594  \n",
       "X01  0.086368  0.009363 -0.268953  0.170725  \n",
       "X02  0.043103  0.195065  0.112824 -0.287004  \n",
       "X03 -0.006028  0.029519 -0.006292 -0.005415  \n",
       "X04 -0.002504 -0.006653  0.042886  0.002213  \n",
       "X05 -0.292621  0.115454  0.021566  0.369986  \n",
       "X06 -0.228867  0.054893 -0.274311  0.376340  \n",
       "X07  1.000000 -0.145627 -0.132451 -0.056175  \n",
       "X08 -0.145627  1.000000 -0.316079  0.209655  \n",
       "X09 -0.132451 -0.316079  1.000000  0.374650  \n",
       "y   -0.056175  0.209655  0.374650  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded our dataset we can use the output of the cells above in order to explore the data.\\\n",
    "We can see that our dataset is composed of 11 columns (one is the target) and 1000 rows.\\\n",
    "First of all we can use the function describe to get some basic statistics about the dataset.\n",
    "From the output of the describe function we can see that the mean of the columns from X00 to X02 and from X05 to X09 are almost the same, so theese columns have almost the same distribution, while the columns X03 and X04 have a different distribution resulting more skewed.\\\n",
    "Also the target column has a different distribution from the other columns, as we can see from the mean and the standard deviation.\\\n",
    "Theese informations above can also be verified by looking at the boxplot. Here we can see that the columns X03 and X04 (and also the target column) have a different distribution from the other columns, while the columns X00 to X02 and from X05 to X09 have a similar distribution.\\\n",
    "We can now look at the correlation matrix between the columns. If we consider the correlation between the columns and the target (the last column/row of the correlation matrix), we can see that columns X03, X04 and X07 have a correlation in absolute value less than 0.15 so they are relly not correlated with the target."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set with 800 rows and 10 columns\n",
      "Test set with 200 rows and 10 columns\n"
     ]
    }
   ],
   "source": [
    "# we now split the dataset into X, y and extract the training and test sets\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "print(f'Training set with {X_train.shape[0]} rows and {X_train.shape[1]} columns')\n",
    "print(f'Test set with {X_test.shape[0]} rows and {X_test.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (on train set): 0.8731890168220966\n",
      "RMSE (on test set): 0.8550066730486878\n"
     ]
    }
   ],
   "source": [
    "# we are now training a linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "y_pred_train = lin_reg.predict(X_train)\n",
    "y_pred_test = lin_reg.predict(X_test)\n",
    "# we can compute RMSE from MSE using np.sqrt or using the squared parameter = False, as shown below\n",
    "print(f'RMSE (on train set): {np.sqrt(mean_squared_error(y_train, y_pred_train))}')\n",
    "print(f'RMSE (on test set): {np.sqrt(mean_squared_error(y_test, y_pred_test))}')\n",
    "\n",
    "# alternative way to compute RMSE\n",
    "# print(f'RMSE = {mean_squared_error(y_test, y_pred, squared=False)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X00</th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.026036</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>-0.007113</td>\n",
       "      <td>0.022166</td>\n",
       "      <td>3.288439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011618</td>\n",
       "      <td>0.025699</td>\n",
       "      <td>-0.026818</td>\n",
       "      <td>-0.012447</td>\n",
       "      <td>0.029382</td>\n",
       "      <td>-0.036920</td>\n",
       "      <td>-0.016464</td>\n",
       "      <td>-2.333510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027478</td>\n",
       "      <td>0.009282</td>\n",
       "      <td>-0.020700</td>\n",
       "      <td>-0.004157</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>-0.012983</td>\n",
       "      <td>2.259783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003170</td>\n",
       "      <td>-0.001697</td>\n",
       "      <td>-0.028924</td>\n",
       "      <td>0.027526</td>\n",
       "      <td>0.012792</td>\n",
       "      <td>-0.011102</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>2.939127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.039508</td>\n",
       "      <td>-0.009104</td>\n",
       "      <td>0.021215</td>\n",
       "      <td>0.018246</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>1.623948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        X00       X01       X02       X05       X06       X08       X09  \\\n",
       "0 -0.016771 -0.026036 -0.001474  0.023372  0.003706 -0.007113  0.022166   \n",
       "1 -0.011618  0.025699 -0.026818 -0.012447  0.029382 -0.036920 -0.016464   \n",
       "2  0.027478  0.009282 -0.020700 -0.004157  0.008240  0.010821 -0.012983   \n",
       "3 -0.003170 -0.001697 -0.028924  0.027526  0.012792 -0.011102  0.015352   \n",
       "4 -0.039508 -0.009104  0.021215  0.018246 -0.000294  0.004178  0.014846   \n",
       "\n",
       "          y  \n",
       "0  3.288439  \n",
       "1 -2.333510  \n",
       "2  2.259783  \n",
       "3  2.939127  \n",
       "4  1.623948  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theese are the columns with a correlation in absolute value less than 0.15\n",
    "to_drop = ['X03', 'X04', 'X07']\n",
    "df_red = df.drop(to_drop, axis=1)\n",
    "# checking if we dropped the right columns\n",
    "df_red.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the new dataset reduced into X_red and y_red\n",
    "\n",
    "X_red = df_red.drop(target, axis=1)\n",
    "y_red = df_red[target]\n",
    "\n",
    "# and generate the training and test sets with the dataset reduced\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_red, y_red, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (on reduced train set): 1.0082876893559303\n",
      "RMSE (on reduced test set): 0.9624394299596234\n"
     ]
    }
   ],
   "source": [
    "lin_reg_red = LinearRegression()\n",
    "lin_reg_red.fit(X_train_red, y_train_red)\n",
    "y_pred_train_red = lin_reg_red.predict(X_train_red)\n",
    "y_pred_test_red = lin_reg_red.predict(X_test_red)\n",
    "print(f'RMSE (on reduced train set): {np.sqrt(mean_squared_error(y_train_red, y_pred_train_red))}')\n",
    "print(f'RMSE (on reduced test set): {np.sqrt(mean_squared_error(y_test_red, y_pred_test_red))}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (on reduced train set): 0.0\n",
      "RMSE (on reduced test set): 1.893770036036949\n",
      "Max depth of the tree: 17\n"
     ]
    }
   ],
   "source": [
    "dt_reg = DecisionTreeRegressor(random_state=random_state)\n",
    "dt_reg.fit(X_train_red, y_train_red)\n",
    "y_dt_train = dt_reg.predict(X_train_red)\n",
    "y_dt_test = dt_reg.predict(X_test_red)\n",
    "\n",
    "print(f'RMSE (on reduced train set): {np.sqrt(mean_squared_error(y_train_red, y_dt_train))}')\n",
    "print(f'RMSE (on reduced test set): {np.sqrt(mean_squared_error(y_test_red, y_dt_test))}')\n",
    "\n",
    "max_dept = dt_reg.get_depth()\n",
    "print(f'Max depth of the tree: {max_dept}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.0581721643048145\n",
      "Best max_depth: {'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': np.arange(1, max_dept+1)}\n",
    "\n",
    "grid_dt = GridSearchCV(DecisionTreeRegressor(random_state=random_state), param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_dt.fit(X_train_red, y_train_red)\n",
    "print(f'Best RMSE: {-grid_dt.best_score_}')\n",
    "print(f'Best max_depth: {grid_dt.best_params_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have fitted the several models we can use the output of the cells above in order to compare the models.\\\n",
    "We can clearly see that the best model is the first multivariate linear regressor, trained on the full dataset without dropping the low-correlated columns.\\\n",
    "This can be due to the fact that, depite the low correlation between the columns and the target, the dropped columns added together with the other columns can be helpful for the model in finding better patterns.\\\n",
    "By looking at the DecisionTreeRegressor results we can state that this model is worse than the LinearRegression both using the standard hyperparamter and the best hyperparameter found by the GridSearchCV.\\\n",
    "This can be due to the fact that the DecisionTreeRegressor aims to find the best features on which applying a split, without taking into account the conjunction of different features in order to find more interesting patterns.\\\n",
    "Also the optimization of the max_depth using cross-validation did not provided a reduction of the error. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
